{"cells":[{"cell_type":"markdown","id":"12a46dcc-0d3d-4392-9f28-5f297ad97253","metadata":{},"outputs":[],"source":["\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0120EN-SkillsNetwork/images/IDSN-logo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"\u003e\n"]},{"cell_type":"markdown","id":"4cc68721-4edb-4f54-b67c-7659c9fe87ba","metadata":{},"outputs":[],"source":["# Lab: Scaling on CPU and GPU\n","\n","Welcome to the lab, first we wanna make sure we are on TensorFlow 2.x\n","\n","Please start with 1 vCPU and then use 2, 4, 8 and 16 (and optionally 1 or 2 GPUs)\n","\n","Note down execution times and compute/plot scale up factor\n"]},{"cell_type":"code","id":"a5faff85-e35d-4a1f-bac3-bb32d1ca3222","metadata":{},"outputs":[],"source":["!pip install tensorflow==2.2.0"]},{"cell_type":"code","id":"05041030-1e38-48f9-b972-7e7ac5f94c5a","metadata":{},"outputs":[],"source":["import tensorflow as tf\nimport time\nimport numpy as np\nprint(tf.__version__)\n\n\n\nfrom IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown('# \u003cspan style=\"color:red\"\u003e'+string+'\u003c/span\u003e'))\n\n\nif not tf.__version__ == '2.2.0':\n    printmd('\u003c\u003c\u003c\u003c\u003c!!!!! Please install TensorFlow 2.2.0 and PLEASE RESTART the jupyter kernel using the menue above !!!!!\u003e\u003e\u003e\u003e\u003e')\n\n"]},{"cell_type":"markdown","id":"0b6ddcbb-249c-484b-a683-98fada2d7f64","metadata":{},"outputs":[],"source":["Let's check out if there are GPUs available\n"]},{"cell_type":"code","id":"666a19a0-23e1-405a-8f2a-549529e34d6b","metadata":{},"outputs":[],"source":["if len(tf.config.experimental.list_physical_devices('GPU')) \u003e 0:\n    print('GPUs found, this will be fun!')"]},{"cell_type":"markdown","id":"6cae5cbe-ae48-4869-9e88-11046562f86c","metadata":{},"outputs":[],"source":["Let's create some data (e.g. two random matrices of shape 10000x10000)\n"]},{"cell_type":"code","id":"12094522-7ba9-4889-aed2-8f382542de0a","metadata":{},"outputs":[],"source":["size = 10000\na = tf.random.uniform(shape=[size,size])\nb = tf.random.uniform(shape=[size,size])"]},{"cell_type":"markdown","id":"4cccccd1-18e4-45f5-89d1-72cabcca4da2","metadata":{},"outputs":[],"source":["Let's multiply them together and measure time (execute the following cell at least 3 times and take the minimum to account for cache misses). Please run this notebook in different runtimes configurations to get the execution times.\n"]},{"cell_type":"markdown","id":"c3fac69c-35fc-4129-ae08-cf72fd02bf19","metadata":{},"outputs":[],"source":["To change the execution environment configuration please click on the ![image.png](attachment:image.png) symbol within Watson Studio. In the \"Environment\" tab you can choose and change the \"Environment definition\".\n"]},{"cell_type":"markdown","id":"fb545dbb-eb9c-4afc-84da-787658359e25","metadata":{},"outputs":[],"source":["We recommend that you go the the \"Environment\" tab in the Watson Studio Project settings and create the environments first ![image.png](attachment:image.png)\n"]},{"cell_type":"markdown","id":"57eb13fa-54db-48d0-a905-988e49680bcb","metadata":{},"outputs":[],"source":["Once done, it should look similar to this\n","![image.png](attachment:image.png)\n"]},{"cell_type":"code","id":"0f54c922-dbca-437e-89f2-de4600ef2e0f","metadata":{},"outputs":[],"source":["start = time.time()\nc = tf.matmul(a,b)\nprint(time.time()-start)"]},{"cell_type":"markdown","id":"0f079954-5ece-4fb4-9fa5-544c137461ed","metadata":{},"outputs":[],"source":["Please update the execution times below for the different runtime configurations with your values (1,2,4,8,16 CPU, optional 1,2,4 GPU)\n"]},{"cell_type":"code","id":"1860bbda-6da8-4edf-afc3-2c0c40e26430","metadata":{},"outputs":[],"source":["execution_times_cpu = {\n    'cpu_1x' : 35.3118622303009,\n    'cpu_2x' : 15.228885173797607,\n    'cpu_4x' : 10.392901182174683,\n    'cpu_8x' : 6.591029644012451,\n    'cpu_16x' : 2.9781200885772705  \n}\nexecution_times_cpu"]},{"cell_type":"code","id":"0631e3dd-7163-47f7-bcf0-c68bd264d529","metadata":{},"outputs":[],"source":["execution_times_gpu = {\n    'gpu_1x' : 0.0012249946594238281,\n    'gpu_2x' : 0.0007076263427734375,\n    'gpu_4x' : 0.0006804466247558594   \n}\nexecution_times_gpu"]},{"cell_type":"markdown","id":"6eb7dec2-05fe-4465-a22f-dacde1450757","metadata":{},"outputs":[],"source":["Merge CPU and GPU results\n"]},{"cell_type":"code","id":"22814248-8675-4312-81fd-c59efc96c180","metadata":{},"outputs":[],"source":["execution_times_cpu_gpu = {}\nexecution_times_cpu_gpu.update(execution_times_cpu)\nexecution_times_cpu_gpu.update(execution_times_gpu)\nexecution_times_cpu_gpu"]},{"cell_type":"markdown","id":"8a53f900-f65b-4052-9ee7-4a9fb299004b","metadata":{},"outputs":[],"source":["Compute normalized speedup factors for CPU, GPU and combindes runs\n"]},{"cell_type":"code","id":"2eb19791-57be-4586-8224-e9bbaeb4fad7","metadata":{},"outputs":[],"source":["max_time_cpu = np.max(list(execution_times_cpu.values()))\nmax_time_gpu = np.max(list(execution_times_gpu.values()))\nmax_time_cpu_gpu = np.max(list(execution_times_cpu_gpu.values()))"]},{"cell_type":"code","id":"afe39765-5d72-41cc-a9d8-1b90e9856cf4","metadata":{},"outputs":[],"source":["execution_times_norm_cpu = np.array(1)/(np.array(list(execution_times_cpu.values()))/max_time_cpu)\nexecution_times_norm_gpu = np.array(1)/(np.array(list(execution_times_gpu.values()))/max_time_gpu)\nexecution_times_norm_cpu_gpu = np.array(1)/(np.array(list(execution_times_cpu_gpu.values()))/max_time_cpu_gpu)"]},{"cell_type":"markdown","id":"d6368532-eba9-497d-9579-4a67ce1e4936","metadata":{},"outputs":[],"source":["Plot the results\n"]},{"cell_type":"code","id":"f2ffa23c-c778-4e6a-9c6b-0e62a5df15d1","metadata":{},"outputs":[],"source":["%matplotlib inline\nimport seaborn as sns\nsns.barplot(x=np.array(list(execution_times_cpu.keys())), y=execution_times_norm_cpu).set(ylabel='speedup')"]},{"cell_type":"code","id":"530ede63-724d-4c04-bac4-14d106ee596b","metadata":{},"outputs":[],"source":["sns.barplot(x=np.array(list(execution_times_gpu.keys())), y=execution_times_norm_gpu).set(ylabel='speedup')"]},{"cell_type":"code","id":"918887b3-97e9-494b-8ef5-937733fa4485","metadata":{},"outputs":[],"source":["sns.barplot(x=np.array(list(execution_times_cpu_gpu.keys())), y=execution_times_norm_cpu_gpu).set(ylabel='speedup')"]},{"cell_type":"markdown","id":"130d9ffd-9519-4e1c-99f2-d925c1871b99","metadata":{},"outputs":[],"source":["As you can clearly see going from a single CPU core to a single GPU gives us a speedup of more than four orders of magnitude. So large scale deep learning network training has to be done on GPUs if possible\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}